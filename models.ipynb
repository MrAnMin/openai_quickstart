{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4448e0a5-511b-4869-9d0b-e911b9afa7a6",
   "metadata": {},
   "source": [
    "# Models API\n",
    "\n",
    "使用 Models API 查看和访问 OpenAI 提供的预训练大语言模型\n",
    "\n",
    "[查询token](https://platform.openai.com/tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100fc64-3039-4936-ad28-107a82d0ba24",
   "metadata": {},
   "source": [
    "## List Models\n",
    "\n",
    "列出当前可用的模型，并提供每个模型的基本信息，如所有者和可用性。\n",
    "\n",
    "`data`: 目前OpenAI提供的大语言模型列表，列表中的每一项都对应着一个模型实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31de8c77-c6ee-4441-abb5-041bf7114a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfecd27f-cbd2-437f-b498-8dd45e906b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1568ef9a-510f-4d0d-a230-7686ec59275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e8d9b5c-8790-4109-95ad-a7e315374e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3d0b65-bd22-4573-b76a-d97b1e8970a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
       " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44a7e08-5329-4397-9ec5-232c7d8c1ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.retrieve('gpt-3.5-turbo-1106')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66dcf5-5c5a-455f-868c-0d71838aaf26",
   "metadata": {},
   "source": [
    "### 获取模型 ID 列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "114923a1-41ae-4ea6-921b-8784d1b7c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model.id for model in  models.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e09039e-235a-40b7-9894-d5db0a58f921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-3.5-turbo-1106',\n",
       " 'dall-e-3',\n",
       " 'dall-e-2',\n",
       " 'text-embedding-3-large',\n",
       " 'whisper-1',\n",
       " 'tts-1-hd-1106',\n",
       " 'tts-1-hd',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-4-0613',\n",
       " 'gpt-3.5-turbo-0301',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'gpt-3.5-turbo-instruct-0914',\n",
       " 'gpt-3.5-turbo-16k-0613',\n",
       " 'gpt-4',\n",
       " 'tts-1',\n",
       " 'davinci-002',\n",
       " 'gpt-4-vision-preview',\n",
       " 'gpt-3.5-turbo-instruct',\n",
       " 'babbage-002',\n",
       " 'gpt-4-0125-preview',\n",
       " 'tts-1-1106',\n",
       " 'gpt-4-turbo-preview',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'gpt-4-1106-preview',\n",
       " 'text-embedding-ada-002',\n",
       " 'text-embedding-3-small']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75282c8b-f27e-4947-9b8f-3dd78a7d18aa",
   "metadata": {},
   "source": [
    "### Retrieve Model\n",
    "\n",
    "获取模型实例，提供有关模型的基本信息，例如所有者和权限设置。\n",
    "\n",
    "以``模型为例，解释说明各项参数：\n",
    "\n",
    "1. `created`: 这是模型创建的时间戳，单位为 Unix 时间戳（自1970年1月1日（00:00:00 GMT）以后的秒数）。\n",
    "2. `id`: 这是模型的唯一标识符。在这个例子中，模型的 ID 是 \"text-davinci-003\"。\n",
    "3. `object`: 这个字段表示的是当前对象的类型，在这个例子中，对象是 \"model\"，说明这个 JSON 对象是一个模型。\n",
    "4. `owned_by`: 这个字段表示的是模型的所有者，在这个例子中，模型的所有者是 \"openai-internal\"。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca7a7fc9-daa8-45be-8f1a-cfebebf35b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.retrieve('gpt-3.5-turbo-1106')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b29ee04-49f6-4017-93ba-33f3197e65e7",
   "metadata": {},
   "source": [
    "## 文本内容补全初探（Completions API）[Legacy]\n",
    "\n",
    "使用 Completions API 实现各类文本生成任务\n",
    "\n",
    "主要请求参数说明：\n",
    "- **`model`** （string，必填）\n",
    "\n",
    "  要使用的模型的 ID。可以参考 **模型端点兼容性表*\n",
    "- **`prompt`** （string or array，必填，Defaults to ）\n",
    "\n",
    "  生成补全的提示，编码为字符串、字符串数组、token数组或token数组数。\n",
    "\n",
    "  注意，这是模型在训练过程中看到的文档分隔符，所以如果没有指定提示符，模型将像从新文档的开头一\n",
    "- **`stream`** （boolean，选填，默认 false）\n",
    "\n",
    "  当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容，即会不断地输出内容直到完成响应，流通过 `data: [DONE]` 消息终\n",
    "- **`max_tokens`** （integer，选填，默认是 16）\n",
    "\n",
    "  补全时要生成的最大 token 。\n",
    "\n",
    "  提示 `max_tokens` 的 token 计数不能超过模型的上下文长度。大多数模型的上下文长度为 2048 个token（最新模型除外，它支持 4\n",
    "- **`temperature`** （number，选填，默认是1）\n",
    "\n",
    "  使用哪个采样温度，在 **0和2之间*。\n",
    "\n",
    "  较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和定性。\n",
    "\n",
    "  通常建议修改这个（`temperature` ）或 `top_p` 但两者不能同时存在，二选一。096）止。样生成。*。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d33fbc-0f73-4f35-ac91-71cd10a8be55",
   "metadata": {},
   "source": [
    "## 生成英文文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23d1f50d-7a9d-4ae3-ac02-96670baa46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a25244cb-fdd9-4164-b8fe-cc3041a4a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.completions.create(\n",
    "    model = 'gpt-3.5-turbo-instruct',\n",
    "    prompt = 'Say this is a test',\n",
    "    max_tokens = 7,\n",
    "    temperature = 0 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a88d9a6a-ebed-46ef-bcea-d42019b538ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "print(data.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2692ca-08e5-436d-a4af-22b1794017e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4592404a-5284-4eaf-b541-95bec28e5c28",
   "metadata": {},
   "source": [
    "## 生成中文文本\n",
    "\n",
    "调整 `max_tokens` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7e13369-1695-4098-843f-30fa94335bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.completions.create(\n",
    "    model = 'gpt-3.5-turbo-instruct',\n",
    "    prompt = '讲2个给程序员听得笑话',\n",
    "    max_tokens = 1000,\n",
    "    temperature = 0.5 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbdcddd5-6319-4082-90ca-fca95d201776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1.程序员和老板之间的对话：\n",
      "老板：你能不能把这个项目做得更快一点？\n",
      "程序员：当然可以，但是我需要更多的时间来写代码。\n",
      "老板：为什么？\n",
      "程序员：因为我要花更多的时间来调试和修复你之前要求的修改。\n",
      "\n",
      "2.程序员和产品经理之间的对话：\n",
      "产品经理：我们需要一个功能来实现这个想法。\n",
      "程序员：好的，我会尽力去做。\n",
      "产品经理：但是我需要它在明天就完成。\n",
      "程序员：那我需要一个时间机器。\n"
     ]
    }
   ],
   "source": [
    "print(data.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac01afb-7f0e-4d83-8eb8-2c83834ed1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd44875-fe15-4aa7-ad12-3f037b787997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "openai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
